CSSS508, Week 3: dplyr
====================================================================================
author: Charles Lanfear
date: October 11, 2017
transition: linear
width: 1600
height: 900


Death to Spreadsheets
====================================================================================
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 90)
```

Today we'll talk more about `dplyr`: a package that does in R just about any calculation you've tried to do in Excel, but more *transparently*, *reproducibly*, and *safely*. Don't be the sad research assistant who made this mistake ([Reinhart and Rogoff](http://www.bloomberg.com/news/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history)):

![Reinhart and Rogoff's spreadsheet error](http://rooseveltinstitute.org/wp-content/uploads/styles/large/public/content_images/reinhart_rogoff_coding_error_0.png)


Modifying Data Frames with dplyr
====================================================================================
type: section


But First, Pipes (%>%)
====================================================================================

The `dplyr` package makes use of the [`magrittr`](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html) forward pipe operator, usually called simply a **pipe**. We write pipes like `%>%` (*Cntl-Shift-M*). Pipes take the object on the *left* and apply the function on the *right*: `x %>% f(y) = f(x, y)`. Read out loud: "and then..."

```{r}
library(dplyr)
library(gapminder)
gapminder %>% filter(country == "Canada") %>% head(2)
```

Pipes save us typing, make code readable, and allow chaining like above, so we use them *all the time* when manipulating data frames.


Using Pipes
====================================================================================
incremental: true

Pipes are clearer to read when you have each function on a separate line (inconsistent in these slides because of space constraints).
```{r, eval=FALSE}
take_this_data %>%
    do_first_thing(with = this_value) %>%
    do_next_thing(using = that_value) %>% ...
```

Stuff to the left of the pipe is passed to the *first argument* of the function on the right. Other arguments go on the right in the function. 

If you ever find yourself piping a function where data are not the first argument, use `.` in the data argument instead.
```{r, eval=FALSE}
yugoslavia %>% lm(pop ~ year, data = .)
```


Filtering Rows (subsetting)
====================================================================================

Recall last week we used the `filter()` command to subset data like so:
```{r}
Canada <- gapminder %>%
    filter(country == "Canada")
```

Excel analogue:

![Excel's filter](http://content.gcflearnfree.org/topics/143/ex07_filter.gif)


Another Operator: %in%
====================================================================================

Common use case: want to filter rows to things in some *set*. The `c()` function is how we make **vectors** in R, which are an important data type. We can use `%in%` like `==` but for matching *any item* in the vector on its right.

```{r}
former_yugoslavia <- c("Bosnia and Herzegovina", "Croatia", "Macedonia", "Montenegro", "Serbia", "Slovenia")
yugoslavia <- gapminder %>%
    filter(country %in% former_yugoslavia)
tail(yugoslavia, 2)
```


What Values are Out There? Use distinct()
====================================================================================

You can see all the unique values in your data for combinations of columns using `distinct()`:

```{r}
gapminder %>% distinct(continent, year)
```


Note: distinct() drops unused variables!
====================================================================================

Note that the default behavior of `distinct()` is to drop all unspecified columns. If you want to get distinct rows by certain variables without dropping the others, use `distinct(.keep_all=TRUE)`:

```{r}
gapminder %>% distinct(continent, year, .keep_all=TRUE)
```


Sampling Rows: sample_n()
====================================================================================

We can also filter *at random* to work with a smaller dataset using `sample_n()` or `sample_frac()`.

```{r}
set.seed(413) # makes random numbers repeatable
yugoslavia %>% sample_n(size = 6, replace = FALSE)
```


Sorting: arrange()
====================================================================================

Along with filtering the data to see certain rows, we might want to sort it:

```{r}
yugoslavia %>% arrange(year, desc(pop)) # ascending by year, descending by pop
```


Keeping Columns: select()
====================================================================================

Not only can we limit rows, but we can include specific columns (and put them in the order listed) using `select()`. 

```{r}
yugoslavia %>% select(country, year, pop) %>% head(4)
```


Dropping Columns: select()
====================================================================================

We can instead drop only specific columns with `select()` using `-` signs:

```{r}
yugoslavia %>% select(-continent, -pop, -lifeExp) %>% head(4)
```


Helper Functions for select()
====================================================================================

`select()` has a variety of helper functions like `starts_with()`, `ends_with()`, and `contains()`, or giving a range of continguous columns `startvar:endvar`. These are very useful if you have a "wide" data frame with column names following a pattern or ordering. See `?select`.

![DYS Data Example](http://clanfear.github.io/CSSS508/Lectures/Week3/CSSS508_Week3_dplyr-figure/dys_vars.PNG)

```{r, eval=FALSE}
DYS %>% select(starts_with("married"))
DYS %>% select(ends_with("18"))
```


Renaming Columns with select()
====================================================================================

We can rename columns using `select()`, but that drops everything that isn't mentioned:

```{r}
yugoslavia %>%
    select(Life_Expectancy = lifeExp) %>%
    head(4)
```


Safer: Rename Columns with rename()
====================================================================================

```{r}
yugoslavia %>%
    select(country, year, lifeExp) %>%
    rename(Life_Expectancy = lifeExp) %>%
    head(4)
```


Column Naming Practices
====================================================================================
incremental: true

* *Good* column names will be self-describing. Don't use inscrutable abbreviations to save typing. RStudio's autocompleting functions take away the pain of long variable names: Hit tab while writing code to autocomplete.
* *Valid* "naked" column names can contain upper or lowercase letters, numbers, periods, and underscores. They must start with a letter or period and not be a special reserved word (e.g. `TRUE`, `if`).
* Names are case-sensitive: `Year` and `year` are not the same thing!
* You can include spaces or use reserved words if you put backticks around the name. Spaces can be worth including when preparing data for `ggplot2` or `pander` since you don't have to rename axes or table headings.


Column Name with Space Example
====================================================================================

```{r}
library(pander)
yugoslavia %>% filter(country == "Serbia") %>%
    select(year, lifeExp) %>%
    rename(Year = year, `Life Expectancy` = lifeExp) %>%
    head(5) %>%
    pander(style = "rmarkdown", caption = "Serbian life expectancy")
```


Create New Columns: mutate() and transmute()
====================================================================================

In `dplyr`, you can add new columns to a data frame using `mutate()`. 

You can also add new columns and *drop old ones* using `transmute()`.


mutate() Example
====================================================================================

```{r}
yugoslavia %>% filter(country == "Serbia") %>%
    select(year, pop, lifeExp) %>%
    mutate(pop_million = pop / 1000000,
           life_exp_past_40 = lifeExp - 40) %>%
    head(5)
```


ifelse()
====================================================================================

A common function used in `mutate()` (and in general in R programming) is `ifelse()`. This returns a value depending on logical tests.

```{r, eval=FALSE}
ifelse(test= x==y, yes=if_true, no=if_false)
```

Output from `ifelse()`:
* `ifelse()` returns the value assigned to `if_true` if `x==y` is `TRUE`.

* `ifelse()` returns `if_false` if `x==y` is `FALSE`.

* `ifelse()` returns `NA` if `x==y` is neither `TRUE` nor `FALSE`.

ifelse() Example
====================================================================================

```{r}
yugoslavia %>%
    mutate(short_country = ifelse(country == "Bosnia and Herzegovina", 
                                  "B and H", as.character(country))) %>%
    select(short_country, year, pop) %>%
    arrange(year, short_country) %>%
    head(3)
```


recode()
====================================================================================

`recode()` is another useful function to use inside `mutate()`. Use `recode()` to change specific values to other values. You can change multiple values at the same time using `recode()`. Note if a value has spaces in it, you'll need to put it in backticks!
```{r}
yugoslavia %>% 
  mutate(country = recode(country, `Bosnia and Herzegovina`="B and H",
                                    Montenegro="M")) %>% distinct(country)
```


case_when()
====================================================================================

`case_when()` performs multiple `ifelse()` operations at the same time. `case_when()` allows you to create a new variable with values based on multiple logical statements at the same time. This is useful for making categorical variables or variables from combinations of other variables.

```{r}
gapminder %>% mutate(gdpPercap_ordinal = case_when(
    gdpPercap < 700 ~ "low",
    gdpPercap >= 700 & gdpPercap < 800 ~ "moderate",
    TRUE ~ "high" ) ) # Assigns this value when all other statements are FALSE
```
 

Summarizing with dplyr
====================================================================================
type: section


General Aggregation: summarize()
====================================================================================

`summarize()` takes your rows of data and computes something across them: count how many rows there are, calculate the mean or total, etc. You can use any function that aggregates multiple values into a single one (like `sd()`).

In a spreadsheet:

![Excel equivalent of summing a column](https://osiprodeusodcspstoa01.blob.core.windows.net/en-us/media/5feb1ba8-a0fb-49d1-8188-dcf1ba878a42.jpg)


summarize() Example
====================================================================================

```{r}
yugoslavia %>%
    filter(year == 1982) %>%
    summarize(n_obs = n(),
              total_pop = sum(pop),
              mean_life_exp = mean(lifeExp),
              range_life_exp = max(lifeExp) - min(lifeExp))
```


Avoiding Repetition: summarize_at()
====================================================================================

Maybe you need to calculate the mean and standard deviation of a bunch of columns. With `summarize_at()`, put the variables to compute over first in `vars()` (like `select()` syntax) and put the functions to use in a `funs()` after.

```{r}
yugoslavia %>%
    filter(year == 1982) %>%
    summarize_at(vars(lifeExp, pop), funs(mean, sd))
```

Avoiding Repetition: Other functions
====================================================================================

There are additional `dplyr` functions similar to `summarize_at()`:

* `summarize_all()` and `mutate_all()` summarize / mutate *all* variables sent to them in the same way. For instance, getting the mean and standard deviation of an entire dataframe:

```
dataframe %>% summarize_all(funs(mean, sd))
```

* `summarize_if()` and `mutate_if()` summarize / mutate all variables that satisfy some logical condition. For instance, summarizing every numeric column in a dataframe at once:

```
dataframe %>% summarize_if(is.numeric, funs(mean, sd))
```

You can use all of these to avoid typing out the same code repeatedly!

Splitting Data into Groups: group_by()
====================================================================================

The special function `group_by()` changes how functions operate on the data, most importantly `summarize()`. TFunctions after `group_by` are computed *within each group* as defined by variables given, rather than over all rows at once. Typically the variables you group by will be integers, factors, or characters, and not continuous real values.

Excel analogue: pivot tables

![Pivot table](http://www.excel-easy.com/data-analysis/images/pivot-tables/two-dimensional-pivot-table.png)


group_by() example
====================================================================================


```{r}
yugoslavia %>% group_by(year) %>%
    summarize(num_countries = n_distinct(country),
              total_pop = sum(pop),
              total_gdp_per_cap = sum(pop * gdpPercap) / total_pop) %>%
    head(5)
```


Window Functions
====================================================================================

Grouping can also be used with `mutate()` or `filter()` to give rank orders within a group, lagged values, and cumulative sums. Much more on window functions is in a [vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html).

```{r}
yugoslavia %>% select(country, year, pop) %>%
    filter(year >= 2002) %>% group_by(country) %>%
    mutate(lag_pop = lag(pop, order_by = year),
           pop_chg = pop - lag_pop) %>% head(4)
```


Joining (Merging) Data Frames
====================================================================================
type: section


When Do We Need to Join Tables?
====================================================================================

* Want to make columns using criteria too complicated for `ifelse()` or `case_when()`
* Combine data stored in separate places: e.g. UW registrar information with student homework grades

Excel equivalents: `VLOOKUP`, `MATCH`

![VLOOKUP example](https://cdn.ablebits.com/_img-blog/excel-vlookup/excel-vlookup.png)


Joining: Conceptually
====================================================================================

We need to think about the following when we want to merge data frames `A` and `B`:

* Which rows are we keeping from each data frame?
* Which columns are we keeping from each data frame?
* Which variables determine whether rows match?


Types of Joins: Rows and columns to keep
====================================================================================

* `A %>% inner_join(B)`: keep rows from `A` that match rows in `B`, columns from both `A` and `B`
* `A %>% left_join(B)`: keep all rows from `A`, matched with `B` wherever possible (`NA` when not), columns from both `A` and `B`
* `A %>% right_join(B)`: keep all rows from `B`, matched with `A` wherever possible (`NA` when not), columns from both `A` and `B`
* `A %>% full_join(B)`: keep all rows from either `A` or `B`, matched wherever possible (`NA` when not), columns from both `A` and `B`
* `A %>% semi_join(B)`: keep rows from `A` that match rows in `B`, columns from just `A`
* `A %>% anti_join(B)`: keep rows from `A` that *don't* match a row in `B`, columns from just `A`


Matching Criteria
====================================================================================

We say rows should match because they have some columns containing the same value. We list these in a `by = ` argument to the join.

* No `by`: matches using all variables in `A` and `B` that have identical names
* `by = c("var1", "var2", "var3")`: matches on identical values of `var1`, `,var2`, `var3` in both `A` and `B`
* `by = c("Avar1" = "Bvar1", "Avar2" = "Bvar2")`: matches identical values of `Avar1` variable in `A` to `Bvar1` variable in `B`, and `Avar2` variable in `A` to `Bvar2` variable in `B`

Note: If there are multiple matches, you'll get one row for each possible combo (except with `semi_join()` and `anti_join()`).

Need to get more complicated? You may want to learn SQL.


nycflights13 Data
====================================================================================

We'll use data in the [`nycflights13` package](https://cran.r-project.org/web/packages/nycflights13/nycflights13.pdf). Install and load it:
```{r}
# install.packages("nycflights13") # Uncomment to run
library(nycflights13)
```

It includes five dataframes, some of which contain missing data (`NA`):

* `flights`: flights leaving JFK, LGA, or EWR in 2013
* `airlines`: airline abbreviations
* `airports`: airport metadata
* `planes`: airplane metadata
* `weather`: hourly weather data for JFK, LGA, and EWR

Join Example #1
====================================================================================

Who manufactures the planes that flew to Seattle?
```{r}
flights %>% filter(dest == "SEA") %>% select(tailnum) %>%
    left_join(planes %>% select(tailnum, manufacturer), by = "tailnum") %>%
    distinct(manufacturer, .keep_all=T)
```

Join Example #2
====================================================================================

Which airlines had the most flights to Seattle from NYC?
```{r}
flights %>% filter(dest == "SEA") %>% select(carrier) %>%
    left_join(airlines, by = "carrier") %>%
    group_by(name) %>% tally() %>% arrange(desc(n))
```


Join Example #3
====================================================================================

Is there a relationship between departure delays and wind gusts?

```{r, warning=FALSE, message=FALSE, eval=FALSE}
library(ggplot2)
flights %>% select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    # removing rows with missing values
    filter(!is.na(dep_delay) & !is.na(wind_gust)) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
    geom_point() + geom_smooth()
```

Wind Gusts and Delays
====================================================================================

```{r, warning=FALSE, message=FALSE, echo=FALSE, cache=TRUE, fig.width = 10, fig.height = 5.5, dpi=300, out.width="1100px", out.height="600px"}
library(ggplot2)
flights %>% select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    # removing rows with missing values
    filter(!is.na(dep_delay) & !is.na(wind_gust)) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
    geom_point() + geom_smooth()
```

Redo After Removing Extreme Outliers, Just Trend
====================================================================================

```{r, warning=FALSE, message=FALSE, eval=FALSE}
flights %>% select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    filter(!is.na(dep_delay) & !is.na(wind_gust) & wind_gust < 250) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
    geom_smooth() + theme_bw(base_size = 16) +
    xlab("Wind gusts in departure hour (mph)") +
    ylab("Average departure delay (minutes)")
```

Wind Gusts and Delays: Mean Trend
====================================================================================

```{r, warning=FALSE, message=FALSE, echo=FALSE, cache=TRUE, fig.width = 10, fig.height = 5.5, dpi=300, out.width="1100px", out.height="600px"}
flights %>% select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    filter(!is.na(dep_delay) & !is.na(wind_gust) & wind_gust < 250) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
    geom_smooth() + theme_bw(base_size = 16) +
    xlab("Wind gusts in departure hour (mph)") +
    ylab("Average departure delay (minutes)")
```


Tinkering Suggestions
====================================================================================

Some possible questions to investigate:

* What are the names of the most common destination airports?
* Which airlines fly from NYC to your home city?
* Is there a relationship between departure delays and precipitation?
* Use the time zone data in `airports` to convert flight arrival times to NYC local time.
    + What is the distribution of arrival times for flights leaving NYC over a 24 hour period?
    + Are especially late or early arrivals particular to some regions or airlines?

**Warning:** `flights` has `r nrow(flights)` rows, so if you do a sloppy join, you can end up with **many** matches per observation and have the data *explode* in size.


Homework 3
====================================================================================
type: section

Pick something to look at in the `nycflights13` data and write up a .Rmd file showing your investigation. Upload both the .Rmd file and the .html file to Canvas. You must use at least once: `mutate()`, `summarize()`, `group_by()`, and any join. *Include at least one nicely formatted plot (`ggplot2`) and one table (`pander`)*. In plots and tables, use "nice" variable names (try out spaces!) and rounded values (<= 3 digits).

This time, *include all your code in your output document* (`echo=TRUE`), using comments and line breaks separating commands so that it is clear to a peer what you are doing (or trying to do!). You must write up your observations briefly in words as well.  Note: If you want to see the `nycflights13` dataframes in the environment, you will need to load *each one* individually (`airlines`, `airports`, `flights`, `planes`, and `weather`) using `data(dataframe_name)` (e.g. `data(flights)`).

DUE: 11:59 PM, Oct 17th

